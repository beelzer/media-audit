# =============================================================================
# Media Audit CI/CD Pipeline
# =============================================================================
# This workflow implements advanced CI/CD patterns including matrix testing,
# intelligent caching, security scanning, and automated releases.
#
# Features:
# - Matrix testing across multiple OS and Python versions
# - Advanced caching with fallback strategies
# - Parallel job execution with dependency management
# - Security scanning (CodeQL, dependency vulnerabilities, secrets)
# - Test coverage reporting with badge generation
# - Performance benchmarking and metrics tracking
# - Smart conditional execution based on file changes
# - PR comment automation with detailed reports
# - Release automation with semantic versioning
# - SARIF uploads for security findings
# - Artifact management and retention policies
# =============================================================================

name: CI/CD Pipeline

on:
  push:
    branches: [main, develop]
    tags:
      - 'v*'
    paths-ignore:
      - '**.md'
      - 'docs/**'
      - '.gitignore'
      - 'LICENSE'
      - '.github/ISSUE_TEMPLATE/**'
      - '.github/PULL_REQUEST_TEMPLATE/**'
  
  pull_request:
    branches: [main, develop]
    types: [opened, synchronize, reopened, ready_for_review]
    paths-ignore:
      - '**.md'
      - 'docs/**'
      - '.gitignore'
      - 'LICENSE'
  
  schedule:
    # Run security scans daily at 2 AM UTC
    - cron: '0 2 * * *'
  
  workflow_dispatch:
    inputs:
      debug_enabled:
        description: 'Enable debug mode'
        type: boolean
        required: false
        default: false
      skip_tests:
        description: 'Skip test suite'
        type: boolean
        required: false
        default: false

# Cancel in-progress runs for the same PR/branch
concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: ${{ github.event_name == 'pull_request' }}

# Default permissions for all jobs
permissions:
  contents: read
  pull-requests: write
  issues: write
  checks: write
  actions: read
  security-events: write
  statuses: write

env:
  # Global environment variables
  PYTHON_VERSION_DEFAULT: "3.13"
  UV_CACHE_DIR: ~/.cache/uv
  UV_NO_PROGRESS: 1
  PYTEST_TIMEOUT: 300
  COVERAGE_THRESHOLD: 80
  CACHE_VERSION: v2  # Increment to invalidate all caches
  NODE_VERSION: "20"
  
  # Performance tuning
  PYTHONUNBUFFERED: 1
  FORCE_COLOR: 1
  PIP_DISABLE_PIP_VERSION_CHECK: 1
  
  # Security
  DETECT_SECRETS_VERSION: "1.5.0"
  BANDIT_VERSION: "1.8.6"

jobs:
  # =============================================================================
  # Change Detection - Determines which tests/checks to run
  # =============================================================================
  changes:
    name: Detect Changes
    runs-on: ubuntu-latest
    outputs:
      python: ${{ steps.filter.outputs.python }}
      tests: ${{ steps.filter.outputs.tests }}
      dependencies: ${{ steps.filter.outputs.dependencies }}
      workflows: ${{ steps.filter.outputs.workflows }}
      docs: ${{ steps.filter.outputs.docs }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v5
        with:
          fetch-depth: 2  # Need previous commit for comparison
      
      - name: Detect file changes
        uses: dorny/paths-filter@v3
        id: filter
        with:
          filters: |
            python:
              - 'src/**/*.py'
              - 'tests/**/*.py'
              - '*.py'
            tests:
              - 'tests/**'
              - 'src/**/*.py'
              - 'pyproject.toml'
            dependencies:
              - 'pyproject.toml'
              - 'uv.lock'
              - 'requirements*.txt'
            workflows:
              - '.github/workflows/**'
              - '.github/actions/**'
            docs:
              - 'docs/**'
              - 'mkdocs.yml'
              - '*.md'

  # =============================================================================
  # Dependency Security Scanning
  # =============================================================================
  dependency-review:
    name: Dependency Security Review
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v5
      
      - name: Dependency Review
        uses: actions/dependency-review-action@v5
        with:
          fail-on-severity: high
          deny-licenses: GPL-3.0, AGPL-3.0
          comment-summary-in-pr: always
          warn-only: ${{ github.event_name == 'pull_request' && github.event.pull_request.draft }}

  # =============================================================================
  # Static Code Analysis with CodeQL
  # =============================================================================
  codeql:
    name: CodeQL Security Analysis
    runs-on: ubuntu-latest
    if: github.event_name != 'schedule' || github.ref == 'refs/heads/main'
    
    strategy:
      fail-fast: false
      matrix:
        language: ['python']
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v5
      
      - name: Initialize CodeQL
        uses: github/codeql-action/init@v3
        with:
          languages: ${{ matrix.language }}
          queries: security-and-quality
      
      - name: Autobuild
        uses: github/codeql-action/autobuild@v3
      
      - name: Perform CodeQL Analysis
        uses: github/codeql-action/analyze@v3
        with:
          category: "/language:${{ matrix.language }}"
          upload: true
          add-pr-comment: true

  # =============================================================================
  # Lint and Format Checks
  # =============================================================================
  lint:
    name: Lint & Format (${{ matrix.check }})
    runs-on: ubuntu-latest
    needs: changes
    if: needs.changes.outputs.python == 'true' || needs.changes.outputs.workflows == 'true'
    
    strategy:
      fail-fast: false
      matrix:
        check:
          - ruff-lint
          - ruff-format
          - mypy
          - pre-commit
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v5
        with:
          fetch-depth: 0  # Full history for pre-commit
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION_DEFAULT }}
      
      - name: Cache management
        uses: actions/cache@v4
        id: cache
        with:
          path: |
            ${{ env.UV_CACHE_DIR }}
            ~/.cache/pre-commit
            ~/.mypy_cache
          key: lint-${{ runner.os }}-${{ matrix.check }}-${{ hashFiles('pyproject.toml', 'uv.lock', '.pre-commit-config.yaml') }}-${{ env.CACHE_VERSION }}
          restore-keys: |
            lint-${{ runner.os }}-${{ matrix.check }}-
            lint-${{ runner.os }}-
      
      - name: Install uv
        uses: astral-sh/setup-uv@v6
        with:
          enable-cache: true
          cache-dependency-glob: |
            pyproject.toml
            uv.lock
      
      - name: Install dependencies
        run: |
          uv pip install --system -e .[dev]
        timeout-minutes: 5
        continue-on-error: false
      
      - name: Run ruff lint
        if: matrix.check == 'ruff-lint'
        run: |
          ruff check src tests --output-format=github --show-fixes
      
      - name: Run ruff format
        if: matrix.check == 'ruff-format'
        run: |
          ruff format --check src tests --diff
      
      - name: Run mypy
        if: matrix.check == 'mypy'
        run: |
          mypy src --strict --no-implicit-reexport --show-error-codes --pretty \
            --html-report mypy-report --junit-xml mypy-junit.xml || true
          mypy src --strict --no-implicit-reexport --show-error-codes
      
      - name: Run pre-commit
        if: matrix.check == 'pre-commit'
        run: |
          pre-commit run --all-files --show-diff-on-failure --color=always
      
      - name: Upload mypy results
        if: matrix.check == 'mypy' && always()
        uses: actions/upload-artifact@v4
        with:
          name: mypy-results
          path: |
            mypy-report/
            mypy-junit.xml
          retention-days: 7
          if-no-files-found: ignore

  # =============================================================================
  # Security Scanning Suite
  # =============================================================================
  security:
    name: Security Scan (${{ matrix.scanner }})
    runs-on: ubuntu-latest
    needs: changes
    if: needs.changes.outputs.python == 'true' || github.event_name == 'schedule'
    
    strategy:
      fail-fast: false
      matrix:
        scanner:
          - bandit
          - safety
          - secrets
          - trivy
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v5
        with:
          fetch-depth: 0  # Full history for secrets scanning
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION_DEFAULT }}
      
      - name: Cache management
        uses: actions/cache@v4
        with:
          path: ${{ env.UV_CACHE_DIR }}
          key: security-${{ runner.os }}-${{ matrix.scanner }}-${{ hashFiles('pyproject.toml') }}-${{ env.CACHE_VERSION }}
          restore-keys: |
            security-${{ runner.os }}-${{ matrix.scanner }}-
      
      - name: Install uv
        uses: astral-sh/setup-uv@v6
      
      - name: Run Bandit
        if: matrix.scanner == 'bandit'
        run: |
          uv pip install --system bandit[sarif]
          bandit -r src/ -f sarif -o bandit-results.sarif -ll || true
          bandit -r src/ -f json -o bandit-results.json -ll || true
          bandit -r src/ -ll
      
      - name: Run Safety check
        if: matrix.scanner == 'safety'
        run: |
          uv pip install --system safety
          uv pip freeze --system | safety check --stdin --json --output safety-report.json || true
          uv pip freeze --system | safety check --stdin
        continue-on-error: true
      
      - name: Run detect-secrets
        if: matrix.scanner == 'secrets'
        run: |
          uv pip install --system detect-secrets==${{ env.DETECT_SECRETS_VERSION }}
          detect-secrets scan --baseline .secrets.baseline
          detect-secrets audit .secrets.baseline
      
      - name: Run Trivy
        if: matrix.scanner == 'trivy'
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'
          severity: 'CRITICAL,HIGH,MEDIUM'
          ignore-unfixed: true
      
      - name: Upload SARIF results
        if: always() && (matrix.scanner == 'bandit' || matrix.scanner == 'trivy')
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: ${{ matrix.scanner }}-results.sarif
          category: ${{ matrix.scanner }}
        continue-on-error: true
      
      - name: Upload security reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: security-${{ matrix.scanner }}-results
          path: |
            *-results.sarif
            *-results.json
            *-report.json
          retention-days: 30
          if-no-files-found: ignore

  # =============================================================================
  # Test Suite with Coverage
  # =============================================================================
  test:
    name: Test ${{ matrix.os }} / Py${{ matrix.python-version }}${{ matrix.experimental && ' (experimental)' || '' }}
    runs-on: ${{ matrix.os }}
    needs: [changes, lint]
    if: >-
      (needs.changes.outputs.python == 'true' || needs.changes.outputs.tests == 'true' || needs.changes.outputs.workflows == 'true')
      && github.event.inputs.skip_tests != 'true'
    
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: ["3.13"]
        experimental: [false]
        include:
          # Test on latest Python beta/rc if available
          - os: ubuntu-latest
            python-version: "3.14"
            experimental: true
          # Test on minimum supported version
          - os: ubuntu-latest
            python-version: "3.13"
            experimental: false
            coverage: true
    
    continue-on-error: ${{ matrix.experimental }}
    
    timeout-minutes: 30
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v5
        with:
          fetch-depth: 0  # Full history for coverage reports
      
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          allow-prereleases: ${{ matrix.experimental }}
      
      - name: Display system information
        run: |
          python --version
          python -c "import sys; print(sys.version)"
          echo "Runner OS: ${{ runner.os }}"
          echo "Matrix OS: ${{ matrix.os }}"
      
      # Advanced caching strategy with multiple layers
      - name: Cache uv packages
        uses: actions/cache@v4
        id: cache-uv
        with:
          path: ${{ env.UV_CACHE_DIR }}
          key: test-uv-${{ runner.os }}-${{ matrix.python-version }}-${{ hashFiles('uv.lock', 'pyproject.toml') }}-${{ env.CACHE_VERSION }}
          restore-keys: |
            test-uv-${{ runner.os }}-${{ matrix.python-version }}-
            test-uv-${{ runner.os }}-
      
      - name: Cache test data
        uses: actions/cache@v4
        with:
          path: |
            .pytest_cache
            tests/.test_cache
          key: test-data-${{ runner.os }}-${{ hashFiles('tests/**/*.py') }}-${{ env.CACHE_VERSION }}
          restore-keys: |
            test-data-${{ runner.os }}-
      
      - name: Install ffmpeg (Ubuntu)
        if: runner.os == 'Linux'
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg
          ffmpeg -version
      
      - name: Install ffmpeg (macOS)
        if: runner.os == 'macOS'
        run: |
          brew install ffmpeg
          ffmpeg -version
      
      - name: Install ffmpeg (Windows)
        if: runner.os == 'Windows'
        run: |
          choco install ffmpeg -y
          ffmpeg -version
      
      - name: Install uv
        uses: astral-sh/setup-uv@v6
        with:
          enable-cache: true
          cache-dependency-glob: |
            pyproject.toml
            uv.lock
      
      - name: Install dependencies with retry
        uses: nick-invision/retry@v3
        with:
          timeout_minutes: 10
          max_attempts: 3
          retry_wait_seconds: 30
          command: |
            uv pip install --system -e .[dev]
      
      - name: Run tests with coverage
        id: test
        run: |
          pytest tests \
            -v \
            --tb=short \
            --strict-markers \
            --timeout=${{ env.PYTEST_TIMEOUT }} \
            --cov=media_audit \
            --cov-report=term-missing:skip-covered \
            --cov-report=xml:coverage.xml \
            --cov-report=html:htmlcov \
            --cov-report=json:coverage.json \
            --junit-xml=junit.xml \
            --maxfail=5 \
            ${{ runner.debug == '1' && '--capture=no' || '' }}
        env:
          COVERAGE_FILE: .coverage.${{ matrix.os }}.${{ matrix.python-version }}
      
      - name: Generate coverage badge
        if: matrix.coverage && success()
        run: |
          uv pip install --system coverage-badge
          coverage-badge -o coverage-badge.svg -f
      
      - name: Check coverage threshold
        if: matrix.coverage
        run: |
          uv pip install --system coverage
          coverage report --fail-under=${{ env.COVERAGE_THRESHOLD }}
        continue-on-error: ${{ matrix.experimental }}
      
      # Performance benchmarking (optional - add when benchmark tests exist)
      - name: Run benchmarks
        if: matrix.os == 'ubuntu-latest' && matrix.python-version == env.PYTHON_VERSION_DEFAULT
        run: |
          # Placeholder for benchmark tests
          # pytest tests/benchmarks --benchmark-only --benchmark-json=benchmark.json
          echo "Benchmarks placeholder"
        continue-on-error: true
      
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.os }}-${{ matrix.python-version }}
          path: |
            junit.xml
            coverage.xml
            coverage.json
            htmlcov/
            coverage-badge.svg
            benchmark.json
            .coverage.*
          retention-days: 14
          if-no-files-found: ignore
      
      - name: Upload coverage to Codecov
        if: matrix.coverage && !matrix.experimental
        uses: codecov/codecov-action@v5
        with:
          files: ./coverage.xml
          flags: unittests
          name: coverage-${{ matrix.os }}-${{ matrix.python-version }}
          fail_ci_if_error: false
          verbose: true
          token: ${{ secrets.CODECOV_TOKEN }}
      
      - name: Report test results
        if: always()
        uses: dorny/test-reporter@v1
        with:
          name: Test Results - ${{ matrix.os }} / Python ${{ matrix.python-version }}
          path: junit.xml
          reporter: java-junit
          fail-on-error: false
          fail-on-empty: false

  # =============================================================================
  # Build and Package Validation
  # =============================================================================
  build:
    name: Build Distribution
    runs-on: ubuntu-latest
    needs: [test, security, lint]
    if: always() && !cancelled()
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v5
        with:
          fetch-depth: 0  # Full history for version calculation
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION_DEFAULT }}
      
      - name: Cache build dependencies
        uses: actions/cache@v4
        with:
          path: ${{ env.UV_CACHE_DIR }}
          key: build-${{ runner.os }}-${{ hashFiles('pyproject.toml') }}-${{ env.CACHE_VERSION }}
          restore-keys: |
            build-${{ runner.os }}-
      
      - name: Install uv
        uses: astral-sh/setup-uv@v6
      
      - name: Install build dependencies
        run: |
          uv pip install --system build twine wheel setuptools
      
      - name: Build distribution
        run: |
          python -m build --sdist --wheel --outdir dist/
          ls -la dist/
      
      - name: Check distribution
        run: |
          twine check dist/* --strict
          python -m zipfile -l dist/*.whl
      
      - name: Test installation
        run: |
          uv venv test-env
          source test-env/bin/activate || test-env\Scripts\activate
          pip install dist/*.whl
          media-audit --version
          pip show media-audit
      
      - name: Calculate checksums
        run: |
          cd dist
          sha256sum * > SHA256SUMS
          cat SHA256SUMS
      
      - name: Upload distribution artifacts
        uses: actions/upload-artifact@v4
        with:
          name: dist
          path: dist/
          retention-days: 60
          if-no-files-found: error

  # =============================================================================
  # Documentation Build
  # =============================================================================
  docs:
    name: Build Documentation
    runs-on: ubuntu-latest
    needs: changes
    if: needs.changes.outputs.docs == 'true' || needs.changes.outputs.python == 'true'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v5
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION_DEFAULT }}
      
      - name: Cache dependencies
        uses: actions/cache@v4
        with:
          path: ${{ env.UV_CACHE_DIR }}
          key: docs-${{ runner.os }}-${{ hashFiles('pyproject.toml') }}-${{ env.CACHE_VERSION }}
          restore-keys: |
            docs-${{ runner.os }}-
      
      - name: Install uv
        uses: astral-sh/setup-uv@v6
      
      - name: Install dependencies
        run: |
          uv pip install --system -e .[docs]
      
      - name: Build documentation
        run: |
          mkdocs build --strict --verbose
        continue-on-error: false
      
      - name: Upload documentation
        uses: actions/upload-artifact@v4
        with:
          name: documentation
          path: site/
          retention-days: 30
          if-no-files-found: ignore

  # =============================================================================
  # PR Comment Reporter
  # =============================================================================
  pr-comment:
    name: PR Test Summary
    runs-on: ubuntu-latest
    needs: [test, lint, security, build]
    if: github.event_name == 'pull_request' && always()
    
    permissions:
      pull-requests: write
      checks: write
    
    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts/
      
      - name: Create PR comment
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = require('path');
            
            // Parse test results
            let coverage = 'N/A';
            let testResults = [];
            
            // Try to read coverage
            try {
              const coverageFiles = fs.readdirSync('artifacts').filter(f => f.startsWith('test-results'));
              for (const dir of coverageFiles) {
                const coverageFile = path.join('artifacts', dir, 'coverage.json');
                if (fs.existsSync(coverageFile)) {
                  const data = JSON.parse(fs.readFileSync(coverageFile, 'utf8'));
                  coverage = `${data.totals.percent_covered.toFixed(1)}%`;
                  break;
                }
              }
            } catch (e) {
              console.log('Could not read coverage:', e);
            }
            
            // Build comment body
            const body = `## ü§ñ CI Test Results
            
            ### Coverage: ${coverage}
            
            | Check | Status |
            |-------|--------|
            | Tests | ${{ needs.test.result == 'success' && '‚úÖ Passed' || '‚ùå Failed' }} |
            | Linting | ${{ needs.lint.result == 'success' && '‚úÖ Passed' || '‚ùå Failed' }} |
            | Security | ${{ needs.security.result == 'success' && '‚úÖ Passed' || '‚ö†Ô∏è Issues Found' }} |
            | Build | ${{ needs.build.result == 'success' && '‚úÖ Success' || '‚ùå Failed' }} |
            
            <details>
            <summary>üìä Detailed Results</summary>
            
            View the full test results in the [Actions tab](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
            
            </details>
            
            *Generated at: ${new Date().toISOString()}*
            `;
            
            // Find or create comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });
            
            const botComment = comments.find(comment =>
              comment.user.type === 'Bot' && comment.body.includes('ü§ñ CI Test Results')
            );
            
            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: body
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: body
              });
            }

  # =============================================================================
  # Release Job
  # =============================================================================
  release:
    name: Release
    runs-on: ubuntu-latest
    needs: [test, lint, security, build]
    if: >-
      github.event_name == 'push' &&
      startsWith(github.ref, 'refs/tags/v') &&
      !contains(github.ref, 'rc') &&
      !contains(github.ref, 'beta') &&
      !contains(github.ref, 'alpha')
    
    environment:
      name: production
      url: https://pypi.org/project/media-audit/
    
    permissions:
      contents: write
      id-token: write  # For trusted publishing
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v5
      
      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          name: dist
          path: dist/
      
      - name: Create GitHub Release
        uses: softprops/action-gh-release@v2
        with:
          files: dist/*
          generate_release_notes: true
          draft: false
          prerelease: false
          fail_on_unmatched_files: true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      
      # Uncomment when ready to publish to PyPI
      # - name: Publish to PyPI
      #   uses: pypa/gh-action-pypi-publish@release/v1
      #   with:
      #     skip-existing: true
      #     verbose: true

  # =============================================================================
  # Final Status Check
  # =============================================================================
  status-check:
    name: CI Status Check
    runs-on: ubuntu-latest
    needs: [test, lint, security, build, codeql]
    if: always()
    
    steps:
      - name: Check status
        run: |
          if [[ "${{ contains(needs.*.result, 'failure') }}" == "true" ]]; then
            echo "‚ùå CI pipeline failed"
            exit 1
          elif [[ "${{ contains(needs.*.result, 'cancelled') }}" == "true" ]]; then
            echo "‚ö†Ô∏è CI pipeline was cancelled"
            exit 1
          else
            echo "‚úÖ CI pipeline passed successfully"
          fi

  # =============================================================================
  # Cleanup old workflow runs and caches
  # =============================================================================
  cleanup:
    name: Cleanup Resources
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule'
    
    permissions:
      actions: write
    
    steps:
      - name: Delete old workflow runs
        uses: Mattraks/delete-workflow-runs@v2
        with:
          token: ${{ github.token }}
          repository: ${{ github.repository }}
          retain_days: 30
          keep_minimum_runs: 10
      
      - name: Cleanup caches
        run: |
          gh extension install actions/gh-actions-cache
          
          echo "Fetching list of cache keys"
          cacheKeys=$(gh actions-cache list -R ${{ github.repository }} --limit 100 | cut -f 1)
          
          ## Delete caches older than 7 days
          for cacheKey in $cacheKeys; do
            echo "Checking cache: $cacheKey"
            cacheDate=$(gh actions-cache list -R ${{ github.repository }} --key "$cacheKey" --limit 1 | cut -f 3)
            if [[ -n "$cacheDate" ]]; then
              cacheAge=$(( ($(date +%s) - $(date -d "$cacheDate" +%s)) / 86400 ))
              if [[ $cacheAge -gt 7 ]]; then
                echo "Deleting cache older than 7 days: $cacheKey"
                gh actions-cache delete "$cacheKey" -R ${{ github.repository }} --confirm
              fi
            fi
          done
        env:
          GH_TOKEN: ${{ github.token }}
        continue-on-error: true

# =============================================================================
# Workflow Metadata
# =============================================================================
# Last Updated: 2024
# Maintainer: Media Audit Team
# Documentation: https://github.com/beelzer/media-audit/wiki/CI-CD
# =============================================================================